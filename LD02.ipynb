{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Araslt/spark/blob/main/LD02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqWakliPv4KT"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SparkContext yra pagrindinė klasė, kuri valdo Spark aplikaciją ir nustato ką ji turėtų daryti.\n",
        "# SparkConf yra klasė, kuri leidžia konfigūruoti Spark aplikacijos nustatymus.\n",
        "# 6ios klasės importuojamos, kad būtų galima sukurti SparkContext objektą, kuris naudojamas valdyti Spark aplikaciją ir SparkConf objektą\n",
        "from pyspark import SparkContext, SparkConf\n",
        "# sc.stop()  # Stop the current SparkContext object\n",
        "conf = SparkConf().setAppName('MyApp')\n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "XYv9XGB01xJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "wx64UVwf1qIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "################## **LD02** #############################\n",
        "3. Sudarykite lentele, kurioje matytusi kiek pristatyta siuntu (\"siuntu skaicius\")\n",
        "bei aptarnauta klientu (\"Sustojimo klientu skaicius\") geografinese\n",
        "zonose (\"geografine zona\") skirtingomis savaites dienomis (\"sustojimo\n",
        "savaites diena\").\n",
        "\n"
      ],
      "metadata": {
        "id": "6qhNAa7PUh0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nuskaitomas  failo turinys su Spark tekstinių failų funkcija\n",
        "# sc.textFile() ir jis išsaugomas kintamajame (RDD objekte) A.\n",
        "A = sc.textFile(\"duom_cut.txt\")\n",
        "\n",
        "# funkcija gauna eilutę iš tekstinio failo kaip argumentą ir\n",
        "# grąžina sąrašą (listą) iš eilučių, kurių kiekviena eilutė yra tekstas tarp }}{{.\n",
        "# gaunamas maždaug toks outputas: ['a}{b}{c}{d', 'e'], jei buvo toks \"{{a}{b}{c}{d}}{{e}}\"\n",
        "def myfmap(line):\n",
        "    line = line.strip()\n",
        "    line = line[2:len(line)-2]\n",
        "    return line.split('}}{{')"
      ],
      "metadata": {
        "id": "izQe5hY4c1Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funkcija gauna atskiras eilutes, kurios yra gaunamos iš ankstesnės funkcijos,\n",
        "# kaip argumentą ir iš jų išskiria klientų skaičių, savaitės dieną,\n",
        "# geografinę zoną ir siuntų skaičių. Tuomet funkcija susikuria du tuple:\n",
        "# pirmasis yra unikalus raktas, susidedantis iš zonos ir savaitės dienos,\n",
        "# o antrasis yra tuple su siuntų skaičiumi ir klientų skaičiumi.\n",
        "# Funkcija grąžina None, jei nebuvo rasti kliento, savaitės dienos,\n",
        "# zonos ar siuntos duomenys.\n",
        "# Funkcijos mymap() argumentas \"stopas\" yra funkcijos myfmap() gražinama reikšmė.\n",
        "def mymap(stopas):\n",
        "    klientai = 0\n",
        "    diena = 0\n",
        "    zona = None\n",
        "    siunta = 0\n",
        "\n",
        "    parstrings = stopas.split('}{')\n",
        "    for parstring in parstrings:\n",
        "        (vardas, reiksme) = parstring.split('=')\n",
        "        if(reiksme != ''):\n",
        "            if(vardas == 'Sustojimo klientu skaicius'):\n",
        "                klientai=int(reiksme)\n",
        "            if(vardas == 'sustojimo savaites diena'):\n",
        "                diena=int(reiksme)\n",
        "            if(vardas == 'siuntu skaicius'):\n",
        "                siunta=int(reiksme)\n",
        "            if(vardas == 'geografine zona'):\n",
        "                zona=reiksme\n",
        "\n",
        "    if(klientai != 0 and diena is not None and zona is not None and siunta != 0):\n",
        "        return ((zona, diena), (siunta, klientai))\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "KNLUfS-Tc66O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatMap(myfmap) funkcija naudoja anksčiau apibrėžtą myfmap funkciją suskaidyti\n",
        "# duomenis pagal }}{{ simbolius.\n",
        "# map(mymap) funkcija naudoja anksčiau apibrėžtą mymap funkciją,\n",
        "# kad apdorotų kiekvieną iš gautų eilučių.\n",
        "# filter(lambda x: x is not None) funkcija atmetė tuos duomenis,\n",
        "# kuriuose nebuvo rasti klientų, savaitės dienos, zonos ar siuntų duomenys.\n",
        "# reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])) funkcija sumažina duomenų kiekį,\n",
        "# apjungdama tokius tuple, kurių raktai sutampa ir išsaugo tų tuple reikšmes,\n",
        "# sumuojant jų siuntų ir klientų skaičių.\n",
        "ATS = A.flatMap(myfmap)\\\n",
        "    .map(mymap)\\\n",
        "    .filter(lambda x: x is not None)\\\n",
        "    .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
        "\n",
        "\n",
        "# Išvesti rezultatus\n",
        "print(ATS.take(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvzKh2b7c_qG",
        "outputId": "f2103523-559b-42aa-e747-4580768ac4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('Z1', 3), (618, 158)), (('Z1', 5), (232, 85)), (('Z3', 5), (9, 4)), (('Z1', 1), (267, 81)), (('Z3', 1), (8, 2))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# sugeneruoti lentelės duomenis iš Spark rezultatų\n",
        "table_data = []\n",
        "for ((zona, diena), (siunta, klientai)) in ATS.collect():\n",
        "    row = {'zona': zona, 'savaites diena': diena, 'siuntu sk.': siunta, 'Sustojimo klientu sk.': klientai}\n",
        "    table_data.append(row)\n",
        "\n",
        "# sukurti pandas lentelę su gautais duomenimis\n",
        "df = pd.DataFrame(table_data)\n",
        "print(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3853d5-3902-4385-d6c0-9330256a8e67",
        "id": "34rVytbyUaT4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   zona  savaites diena  siuntu sk.  Sustojimo klientu sk.\n",
            "0    Z1               3         618                    158\n",
            "1    Z1               5         232                     85\n",
            "2    Z3               5           9                      4\n",
            "3    Z1               1         267                     81\n",
            "4    Z3               1           8                      2\n",
            "5    Z3               3          40                     16\n",
            "6    Z1               2         607                    137\n",
            "7    Z1               0          92                     18\n",
            "8    Z1               4         368                     91\n",
            "9    Z3               0           4                      3\n",
            "10   Z3               2          17                      8\n",
            "11   Z3               4          10                      6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# substitute\n",
        "def mymap(stopas):\n",
        "    mapping = {}\n",
        "    parstrings = stopas.split('}{')\n",
        "    for parstring in parstrings:\n",
        "        (vardas, reiksme) = parstring.split('=')\n",
        "        if reiksme:\n",
        "            mapping[vardas] = reiksme\n",
        "    if all(k in mapping for k in ['Sustojimo klientu skaicius', 'sustojimo savaites diena', 'siuntu skaicius', 'geografine zona']):\n",
        "        return ((mapping['geografine zona'], int(mapping['sustojimo savaites diena'])), (int(mapping['siuntu skaicius']), int(mapping['Sustojimo klientu skaicius'])))\n",
        "    else:\n",
        "        return None\n",
        "# print(mymap('geografine zona=1}{sustojimo savaites diena=2}{siuntu skaicius=3}{Sustojimo klientu skaicius=4'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGicmlnl4He4",
        "outputId": "2adf8c3a-9f5d-4133-804a-72f33c762cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('1', 2), (3, 4))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "#\n",
        "#\n",
        "################## **END LD02** #############################"
      ],
      "metadata": {
        "id": "Jn_98mI3U2cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5khWNcbKUZby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spark is an existing SparkSession\n",
        "df = spark.read.json(\"people.json\")\n",
        "# Displays the content of the DataFrame to stdout\n",
        "df.show()\n",
        "# +----+-------+\n",
        "# | age|   name|\n",
        "# +----+-------+\n",
        "# |null|Michael|\n",
        "# |  30|   Andy|\n",
        "# |  19| Justin|\n",
        "# +----+-------+"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqCyUFB41qL2",
        "outputId": "17fb2fea-b10d-40d6-b74e-d84f85dd1aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+\n",
            "| age|   name|\n",
            "+----+-------+\n",
            "|null|Michael|\n",
            "|  30|   Andy|\n",
            "|  19| Justin|\n",
            "+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "sc = spark.sparkContext\n",
        "lines = sc.textFile(\"people.txt\")\n",
        "parts = lines.map(lambda l: l.split(\",\"))\n",
        "people = parts.map(lambda p: Row(name=p[0],age=int(p[1])))\n",
        "peopledf = spark.createDataFrame(people)"
      ],
      "metadata": {
        "id": "TNwLFHVa6Cm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "people = parts.map(lambda p: Row(name=p[0], age=int(p[1].strip())))\n",
        "# schemaString = \"name age\"\n",
        "fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
        "schema = StructType(fields)\n",
        "spark.createDataFrame(people, schema).show()"
      ],
      "metadata": {
        "id": "HQhgun-F1qPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile(\"duom_cut.txt\")\n",
        "def myfmap(line):\n",
        "  line = line.strip()\n",
        "  line = line[2:len(line)-2]\n",
        "  return line.split('}}{{')\n",
        "\n",
        "def mymap(stopas):\n",
        "  #Sustojimo klientu skaicius\n",
        "  klientai = 0\n",
        "  #sustojimo savaites diena\n",
        "  diena = None\n",
        "  parstrings = stopas.split('}{')\n",
        "  for parstring in parstrings:\n",
        "    (vardas, reiksme) = parstring.split('=')\n",
        "    if(reiksme != ''):\n",
        "      if(vardas == 'Sustojimo klientu skaicius'):\n",
        "        klientai=int(reiksme)\n",
        "      if(vardas == 'sustojimo savaites diena'):\n",
        "        diena=int(reiksme)\n",
        "  #if(klientai != None and diena != None):\n",
        "  return (diena, klientai)\n",
        "ATS = A.flatMap(myfmap)\\\n",
        "  .map(mymap)\\\n",
        "  .filter(lambda kv : kv[0]!=None)\n",
        "\n",
        "#diena != None\n",
        "#print(sustojimai.take(10))\n",
        "print(ATS.take(10))\n",
        "dfl3 = spark.createDataFrame(ATS.map(lambda pora:Row(diena=pora[0],klientai=pora[1])))\n",
        "dfl3.show()"
      ],
      "metadata": {
        "id": "dbaNtSQw1qR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ad5dfc-94f5-4f7a-877d-109fbe8bb07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 0), (3, 1), (3, 1)]\n",
            "+-----+--------+\n",
            "|diena|klientai|\n",
            "+-----+--------+\n",
            "|    2|       1|\n",
            "|    2|       1|\n",
            "|    2|       1|\n",
            "|    2|       1|\n",
            "|    2|       1|\n",
            "|    2|       1|\n",
            "|    2|       1|\n",
            "|    2|       0|\n",
            "|    3|       1|\n",
            "|    3|       1|\n",
            "|    3|       1|\n",
            "|    3|       1|\n",
            "|    3|       2|\n",
            "|    3|       7|\n",
            "|    3|       1|\n",
            "|    3|       1|\n",
            "|    3|       9|\n",
            "|    4|       2|\n",
            "|    4|       1|\n",
            "|    4|       0|\n",
            "+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Laboras3').getOrCreate()\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import udf, log\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "#nuo spark 3.0\n",
        "#spark.conf.set(\"spark.sql.legacy.setCommandRejectsSparkCoreConfs\",\"false\")\n",
        "\n",
        "#spark.conf.set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
        "#spark.conf.set(\"spark.executor.instances\", 4)\n",
        "#spark.conf.set(\"spark.executor.cores\", 4)\n",
        "\n",
        "text_file = spark.sparkContext.textFile(\"duom_cut.txt\")\n",
        "#text_file = sc.textFile(\"hdfs:///user/stud0/labt/duom_cut.txt\")\n",
        "\n",
        "def parsinam(line):\n",
        "\t#line=line[2:len(line)-2]\n",
        "\treturn line[2:len(line)-2].split('}}{{')\n",
        "\n",
        "def parsinam2(line):\n",
        "\tobjs = line.split('}{')\n",
        "\tk1=None\n",
        "\tk3=None\n",
        "\tfor at in objs:\n",
        "\t\ttemp = at.split('=')\n",
        "\t\tif(len(temp)<2):\n",
        "\t\t\tbreak\n",
        "\t\tkey,val=at.split('=')\n",
        "\t\tif(key == 'marsrutas'):\n",
        "\t\t\tk1=val\n",
        "\t\tif(key == 'sustojimo data'):\n",
        "\t\t\tk3=val\n",
        "\tif(k1!=None and k3!=None):\n",
        "\t\treturn (k1+\"_\"+k3,(k3,len(str(k3))))\n",
        "\t#else:\n",
        "\t#\treturn (0,(0,0))\n",
        "\n",
        "fmap = text_file.flatMap(parsinam)\n",
        "#fmap = text_file.flatMap(lambda line:line[2:len(line)-2].split('}}{{'))\n",
        "mmap = fmap.map(parsinam2)\n",
        "\n",
        "##Jusu darbas cia:\n",
        "\n",
        "##Kodas, kito failo nuskaitymas ... duomenu agregavimas\n",
        "routes = spark.read.option(\"header\",True).csv(\"RouteSummary.txt\")\n",
        "routes.printSchema()\n",
        "routes = routes.drop(\"M\", \"BendrasAtstumas\",\"BendrasLaikas\")\n",
        "\n",
        "def makeID(str1, str2):\n",
        "    return str1+\"_\"+str2\n",
        "\n",
        "makeID_UDF = udf(lambda z1,z2: makeID(z1,z2),StringType())\n",
        "\n",
        "routes2 = routes.withColumn('ID', makeID_UDF(\"marsrutas\", \"sustojimo data\")).drop(\"marsrutas\", \"sustojimo data\")\n",
        "routes2.printSchema()\n",
        "\n",
        "routes2.write.csv(\"lentele3\")\n",
        "\n",
        "#listas = routes2.rdd.collect()\n",
        "#textfile = open(\"out.txt\", \"w\")\n",
        "#for element in listas:\n",
        "#\ttextfile.write(element + \"\\n\")\n",
        "#textfile.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##training data formato: (\"prognozuojama reiskme\", \"parametras\")\n",
        "training = mmap.toDF()\n",
        "\n",
        "#regression ...\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# Load training data\n",
        "#training = spark.read.format(\"libsvm\")\\\n",
        "#    .load(\"sample_linear_regression_data.txt\")\n",
        "\n",
        "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "\n",
        "# Fit the model\n",
        "lrModel = lr.fit(training)\n",
        "\n",
        "# Print the coefficients and intercept for linear regression\n",
        "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
        "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
        "\n",
        "# Summarize the model over the training set and print out some metrics\n",
        "trainingSummary = lrModel.summary\n",
        "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
        "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
        "trainingSummary.residuals.show()\n",
        "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
        "print(\"r2: %f\" % trainingSummary.r2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#dfFromRDD1.show()\n",
        "#training = training.withColumnRenamed('marsrutas', 'parametrai')\n",
        "\n",
        "\n",
        "training.printSchema()\n",
        "\n",
        "pandasDF = training.toPandas()\n",
        "pandasDF.head()\n",
        "\n",
        "labels = pandasDF['_1'].to_list()\n",
        "\n",
        "values = pandasDF['_2'].to_list()\n",
        "print(labels)\n",
        "print(values)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20,5))\n",
        "axes[2].scatter(labels,labels, s = 10)\n",
        "\n",
        "#training.plot.scatter(x='label',\n",
        "#                      y='label',\n",
        "#                      c='ats',colormap='viridis',ax=axes[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8qAV6QEz1qU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################################"
      ],
      "metadata": {
        "id": "lNz93KDm1qXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JDWwU8-31qau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jO5eQ6iN1qeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A bus RDD objektas\n",
        "A = sc.textFile(\"ket.txt\").map(lambda line: line.strip().split())\n",
        "print(A.collect())\n",
        "B = A.filter(lambda x: x[1] == 'greitis')\n",
        "print(\"B\", B.collect())\n",
        "B = B.map(lambda x: (x[2],1))\n",
        "print(\"B\", B.collect())\n",
        "B = B.reduceByKey(lambda a, b: a+b)\n",
        "print(\"B\", B.collect())\n",
        "C = A.map(lambda x: (x[2], int(x[1] == 'greitis')))\n",
        "print(\"C\", C.collect())\n",
        "C = C.filter(lambda x: x[1] != 0 )\n",
        "C = C.reduceByKey(lambda a, b: a+b)\n",
        "print(\"C\", C.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he7ghtUeuHwV",
        "outputId": "0e2fad16-200e-437e-b1f2-47d956210611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['1', 'greitis', '1111'], ['2', 'kita', '1111'], ['3', 'kita', '2222'], ['4', 'greitis', '2222'], ['5', 'kita', '3333'], ['6', 'greitis', '2222'], ['7', 'greitis', '2222']]\n",
            "B [['1', 'greitis', '1111'], ['4', 'greitis', '2222'], ['6', 'greitis', '2222'], ['7', 'greitis', '2222']]\n",
            "B [('1111', 1), ('2222', 1), ('2222', 1), ('2222', 1)]\n",
            "B [('2222', 3), ('1111', 1)]\n",
            "C [('1111', 1), ('1111', 0), ('2222', 0), ('2222', 1), ('3333', 0), ('2222', 1), ('2222', 1)]\n",
            "C [('2222', 3), ('1111', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nagrinekime duomenis, aprašancius KET pažeidimus. Tarkime, kad Spark terpeje egzistuoja duomenys\n",
        "A RDD pavidalu, duomenys aprašomi šitais atributais:\n",
        "(a) pažeidimo numeris – sveikas skaicius,\n",
        "(b) pažeidimo rušis – žodis (string),\n",
        "(c) pažeidejo kodas (ID) – sveikas skaicius.\n",
        "Užrašykite Spark kodo fragmenta, kuris suskaiciuotu kiek skirtingi pažeidejai turi rušies \"greitis\"\n",
        "pažeidimu."
      ],
      "metadata": {
        "id": "qAXCv-_Huxmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile(\"ket.txt\").map(lambda line: line.strip().split())\n",
        "B = A.filter(lambda list: (list[1] == 'greitis')).map(lambda list: (list[2],1))\\\n",
        ".reduceByKey(lambda a, b: a+b)\n",
        "print(B.collect())\n",
        "B = A.map(lambda list: (list[2], int(list[1] == 'greitis')))\\\n",
        ".reduceByKey(lambda a, b: a+b)\n",
        "print(B.collect())\n",
        "# print(typr(take(3)))"
      ],
      "metadata": {
        "id": "3eBe7xSpumhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ecd9d7-c22b-406d-c746-a9a17dd17664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('2222', 3), ('1111', 1)]\n",
            "[('2222', 3), ('1111', 1), ('3333', 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SwyzkWmLumya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nagrinekime duomenis, aprašancius poliklinikos pacientu duomenis – pacientu apsilankymus del\n",
        "ligos. Tarkime, kad Spark terpeje egzistuoja duomenys A RDD pavidalu, duomenys aprašomi šitais\n",
        "atributais:\n",
        "(a) Apsilankymo metai – sveikas skaicius,\n",
        "(b) ligos pavadinimas – žodis (string),\n",
        "(c) paciento kodas (ID) – sveikas skaicius.\n",
        "Užrašykite Spark kodo fragmenta, kuris parodytu ar 2019 metais buvo daugiau pacientu apsilankusiu\n",
        "del ligos \"tuberkulioze\" nei 2018 metais (atsakymas gali buti \"taip\"/\"ne\" pavidalu). Pastaba: jeigu\n",
        "tas pats pacientas apsilanke kelis kartus, laikoma kad tai vienas pacientas, apsilankes del ligos tais\n",
        "metais."
      ],
      "metadata": {
        "id": "PW6TNSvm0gqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile('ligos.txt').map(lambda x: x.strip().split())\n",
        "B = A.filter(lambda metai: metai[0] == '2018')\n",
        "print('B', B.collect())\n",
        "B = B.map(lambda x: (x[2], 1))\n",
        "print('B', B.collect())\n",
        "# nera sumavimo a+b, tai bus tik uniklaios reiksmes\n",
        "B = B.reduceByKey(lambda a, b: a)\n",
        "print('B', B.collect())\n",
        "print(B.count())\n",
        "# visi raktai paversti i 1, kad veliau suskaiciuoti suma\n",
        "# B = B.map(lambda x: 'a')\n",
        "B = B.map(lambda x: 1)\n",
        "print('B', B.collect())\n",
        "B = B.reduce(lambda a, b: a+b)\n",
        "print('B', B)\n",
        "C = A.filter(lambda metai: metai[0] == '2019') \\\n",
        ".map(lambda x: (x[2], 1)) \\\n",
        ".reduceByKey(lambda a, b: a) \\\n",
        ".map(lambda id: 1) \\\n",
        ".reduce(lambda a, b: a+b)\n",
        "# paskutini reduce galima pakeisti .count()\n",
        "print(\"C\", C)\n",
        "print('tap' if C>B else \"ne\")\n",
        "\n",
        "D = A.map(lambda l: (l[0], l[2], int(l[1] == 'tuberkulioze')))\n",
        "print(D.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JmX67om5e64",
        "outputId": "d44de963-0f95-40e4-9a17-4f3678e90bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B [['2018', 'liga2', '2222'], ['2018', 'tuberkulioze', '1111']]\n",
            "B [('2222', 1), ('1111', 1)]\n",
            "B [('2222', 1), ('1111', 1)]\n",
            "2\n",
            "B [1, 1]\n",
            "B 2\n",
            "C 3\n",
            "tap\n",
            "[('2020', '1111', 1), ('2020', '2222', 1), ('2020', '1111', 1), ('2019', '1111', 1), ('2019', '2222', 1), ('2019', '1111', 1), ('2019', '3333', 0), ('2019', '1111', 0), ('2018', '2222', 0), ('2018', '1111', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile('ligos.txt').map(lambda line: line.strip().split())\n",
        "B = A.filter(lambda metai: (metai[0] == '2018'))\\\n",
        "  .map(lambda l: (l[2],1))\\\n",
        "  .reduceByKey(lambda a, b:a+b)\n",
        "print(B.collect())\n",
        "print(B.count())\n",
        "co = A.filter(lambda metai: (metai[0] == '2018'))\\\n",
        "  .map(lambda ld: (ld[2],1)).reduceByKey(lambda a, b: a)\\\n",
        "  .map(lambda ld: 1).reduce(lambda x, y: x+y)\n",
        "print(co)\n",
        "\n",
        "co19 = A.filter(lambda metai: (metai[0] == '2019'))\\\n",
        "  .map(lambda ld: (ld[2],1)).reduceByKey(lambda a, b: a).count()\n",
        "print('taip' if co19 > co else 'ne')\n",
        "\n",
        "B=A.map(lambda l : ((l[0],l[2]),int(l[1]=='tuberkulioze')))\\\n",
        "  .reduceByKey(lambda a,b: max(a,b)).map(lambda l:(l[0][0],l[0][1],l[1]))\\\n",
        "  .reduceByKey(lambda a,b:a+b)\n",
        "print(B)"
      ],
      "metadata": {
        "id": "HvgBJNl_um1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ede3cc-ed2e-4ade-ef8b-e5d084c4d6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('2222', 1), ('1111', 1)]\n",
            "2\n",
            "2\n",
            "taip\n",
            "PythonRDD[496] at RDD at PythonRDD.scala:53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ajh-J0Vrum4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Nagrinekime duomenis apie vaistines, saugojancias vaistus, duomenys aprašomi šitais atributais:\n",
        "(a) vaistines ID – sveikas skaicius,\n",
        "(b) vaistu sarašas, vaistai aprašomi šitais atributais:\n",
        "i. pagrindine veiklioji medžiaga – žodis (string),\n",
        "ii. kiekis – realusis skaicius,\n",
        "iii. galiojimo termino data – datos pavidalu, paprastumo delei galite laikyti, kad nurodomi tik\n",
        "metai.\n",
        "Išspreskite šiuos uždavinius:\n",
        "(a) Kiekvienai vaistinei išveskite joje esanciu veikliuju medžiagu saraša."
      ],
      "metadata": {
        "id": "a7HKAH5uKpqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def convertVaistine(vaistine):\n",
        "  id=0\n",
        "  try:\n",
        "    id=int(vaistine[0])\n",
        "  except ValueError:\n",
        "    id=0\n",
        "  sar = json.loads(vaistine[1])\n",
        "  S = set()\n",
        "  for el in sar:\n",
        "    S.add(el[0])\n",
        "  return [id,list(S)]\n",
        "\n",
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .map(convertVaistine)\n",
        "sample = A.collect()\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFTY8Vn-um7c",
        "outputId": "306ab22c-97c5-4a07-a8e1-84d2c60221b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, ['B', 'C', 'A']], [2, ['B', 'C', 'A']], [3, ['B', 'C', 'A']], [5, ['B', 'C', 'A']], [4, ['B', 'C', 'A', 'D']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def fmap(vaistine):\n",
        "  id=0\n",
        "  try:\n",
        "    id=int(vaistine[0])\n",
        "  except ValueError:\n",
        "    id=0\n",
        "  sar = json.loads(vaistine[1])\n",
        "  ats = []\n",
        "  for el in sar:\n",
        "    ats.append(((id,el[0]), 1))\n",
        "  return ats\n",
        "\n",
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .flatMap(fmap).reduceByKey(lambda a,b:a)\\\n",
        "  .map(lambda l:(l[0][0],l[0][1])).reduceByKey(lambda a,b: a+b)\\\n",
        "  .groupByKey().map(lambda l:(l[0],list(l[1])))\n",
        "\n",
        "# print([(id, list(s)) for id,s in A.collect()])\n",
        "print(A.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ck-bg6Xum-X",
        "outputId": "bb9971b1-c899-4ac5-c259-f6b3c775f16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(2, ['CAB']), (4, ['CABD']), (1, ['ABC']), (3, ['ABC']), (5, ['ABC'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VeJ3Bn-nunB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Raskite vaistus, kuriu galiojimo terminas pasibaige.\n"
      ],
      "metadata": {
        "id": "E3RYRWgfKuWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .map(convertVaistine)\n",
        "\n",
        "def fmap(vaistine):\n",
        "  id=0\n",
        "  try:\n",
        "    id=int(vaistine[0])\n",
        "  except ValueError:\n",
        "    id=0\n",
        "  sar = json.loads(vaistine[1])\n",
        "  return sar\n",
        "\n",
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .flatMap(fmap)\n",
        "\n",
        "print(A.take(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIQ8ASPfunL7",
        "outputId": "01d5b7c7-2547-4960-d49a-431b3786af6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['A', 50, 2022], ['A', 15, 2020], ['B', 50, 2025]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyW3zr-sunPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dfsd"
      ],
      "metadata": {
        "id": "p4iMPx46Ltzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .map(convertVaistine)\n",
        "\n",
        "# def fmap(vaistine):\n",
        "#   id=0\n",
        "#   try:\n",
        "#     id=int(vaistine[0])\n",
        "#   except ValueError:\n",
        "#     id=0\n",
        "#   sar = json.loads(vaistine[1])\n",
        "#   return sar\n",
        "\n",
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .flatMap(lambda vaistine: json.loads(vaistine[1])).filter(lambda vaistas:vaistas[2]<2023)\n",
        "\n",
        "print(A.take(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpXa-AnmunST",
        "outputId": "87ee24b9-9c2d-4209-d9be-1a4a1ed6250a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['A', 50, 2022], ['A', 15, 2020], ['C', 150, 2021]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ovo9ZyCTunVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Raskite vaistines, kuriose yra vaistu su pasibaigusiu galiojimo terminu."
      ],
      "metadata": {
        "id": "3Eu5Y14BMcVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .map(convertVaistine)\n",
        "\n",
        "def fmap(vaistine):\n",
        "  id=0\n",
        "  try:\n",
        "    id=int(vaistine[0])\n",
        "  except ValueError:\n",
        "    id=0\n",
        "  sar = json.loads(vaistine[1])\n",
        "  ats = []\n",
        "  for el in sar:\n",
        "    ats.append((id,int(el[2]<2023)))\n",
        "  return ats\n",
        "\n",
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .flatMap(fmap).reduceByKey(lambda a,b:a+b).filter(lambda vaistine:vaistine[1]>0)\n",
        "\n",
        "# print([(id, list(s)) for id,s in A.collect()])\n",
        "print(A.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfsc5WbGunYY",
        "outputId": "b6e9e322-80a7-49e5-f79b-565637e9798f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(2, 4), (4, 5), (1, 4), (3, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mEwx_yH5Md8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Kiekvienai veikliajai medžiagai paskaiciuokite vaistu (iš visu vaistiniu) su pasibaigusiais galiojimo\n",
        "terminais dali."
      ],
      "metadata": {
        "id": "RhzuIoXOO4QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .map(convertVaistine)\n",
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .flatMap(lambda vaistine: json.loads(vaistine[1]))\\\n",
        "  .map(lambda vaistas: (vaistas[0],(vaistas[1], vaistas[1] if vaistas[2]<2023 else 0)))\\\n",
        "  .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1]))\\\n",
        "  .map(lambda vaistas: (vaistas[0], vaistas[1][1]/vaistas[1][0]))\n",
        "\n",
        "print(A.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaynSZJlMd_s",
        "outputId": "8c0fd74e-e3f0-4b93-9f58-d2f8c16e70f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('C', 0.849624060150376), ('A', 0.7678571428571429), ('B', 0.07407407407407407), ('D', 1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-1P3BJCMeC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Raskite 10% vaistiniu su didžiausiais vaistu (iš visu vaistiniu) su pasibaigusiais galiojimo terminais\n",
        "skaiciu ir bendru vaistu skaiciu santykiais."
      ],
      "metadata": {
        "id": "SSw9v7zLR5t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fmap(vaistine):\n",
        "  id=0\n",
        "  try:\n",
        "    id=int(vaistine[0])\n",
        "  except ValueError:\n",
        "    id=0\n",
        "  sar = json.loads(vaistine[1])\n",
        "  ats = []\n",
        "  for el in sar:\n",
        "    ats.append((id,int(el[1],el[1] if int(el([2]<2023) else 0)))\n",
        "  return ats\n",
        "\n",
        "A = sc.textFile('vaistines.txt').map(lambda line: line.strip().split())\\\n",
        "  .flatMap(fmap)."
      ],
      "metadata": {
        "id": "W5-aS_87MeGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCLElmf1R0uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQzf3rO8R0xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1-6LU2gunbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LD02\n",
        "Sudarykite lentele, kurioje matytusi kiek pristatyta siuntu (\"siuntu skaicius\") bei aptarnauta klientu (\"Sustojimo klientu skaicius\") geografinese zonose (\"geografine zona\") skirtingomis savaites dienomis (\"sustojimo savaites diena\")."
      ],
      "metadata": {
        "id": "iM_I400paZgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Užduoties numeris\n",
        "n = 10\n",
        "result = (n % 4) + 1\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLxcI0FQaC-r",
        "outputId": "2230e144-e99a-47db-cd15-b85fb6aed7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# nuskaitomas  failo turinys su Spark tekstinių failų funkcija\n",
        "# sc.textFile() ir jis išsaugomas kintamajame (RDD objekte) A.\n",
        "A = sc.textFile(\"text2.txt\")\n",
        "\n",
        "# funkcija gauna eilutę iš tekstinio failo kaip argumentą ir\n",
        "# grąžina sąrašą iš eilučių, kurių kiekviena eilutė yra tekstas tarp {{ ir }}.\n",
        "# Ši funkcija yra naudojama suskaidant duomenis pagal {{ ir }} simbolius.\n",
        "def myfmap(line):\n",
        "    line = line.strip()\n",
        "    line = line[2:len(line)-2]\n",
        "    return line.split('}}{{')\n",
        "\n",
        "# funkcija gauna atskiras eilutes, kurios yra gaunamos iš ankstesnės funkcijos,\n",
        "# kaip argumentą ir iš jų išskiria klientų skaičių, savaitės dieną,\n",
        "# geografinę zoną ir siuntų skaičių. Tuomet funkcija susikuria du tuple:\n",
        "# pirmasis yra unikalus raktas, susidedantis iš zonos ir savaitės dienos,\n",
        "# o antrasis yra tuple su siuntų skaičiumi ir klientų skaičiumi.\n",
        "# Funkcija grąžina None, jei nebuvo rasti kliento, savaitės dienos,\n",
        "# zonos ar siuntos duomenys.\n",
        "# Funkcijos mymap() argumentas \"stopas\" yra funkcijos myfmap() gražinama reikšmė.\n",
        "def mymap(stopas):\n",
        "    klientai = 0\n",
        "    diena = 0\n",
        "    zona = None\n",
        "    siunta = 0\n",
        "\n",
        "    parstrings = stopas.split('}{')\n",
        "    for parstring in parstrings:\n",
        "        (vardas, reiksme) = parstring.split('=')\n",
        "        if(reiksme != ''):\n",
        "            if(vardas == 'Sustojimo klientu skaicius'):\n",
        "                klientai=int(reiksme)\n",
        "            if(vardas == 'sustojimo savaites diena'):\n",
        "                diena=int(reiksme)\n",
        "            if(vardas == 'siuntu skaicius'):\n",
        "                siunta=int(reiksme)\n",
        "            if(vardas == 'geografine zona'):\n",
        "                zona=reiksme\n",
        "\n",
        "    if(klientai != 0 and diena is not None and zona is not None and siunta != 0):\n",
        "        return ((zona, diena), (siunta, klientai))\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# flatMap(myfmap) funkcija naudoja anksčiau apibrėžtą myfmap funkciją suskaidyti\n",
        "# duomenis pagal {{ ir }} simbolius.\n",
        "# map(mymap) funkcija naudoja anksčiau apibrėžtą mymap funkciją,\n",
        "# kad apdorotų kiekvieną iš gautų eilučių.\n",
        "# filter(lambda x: x is not None) funkcija atmetė tuos duomenis,\n",
        "# kuriuose nebuvo rasti klientų, savaitės dienos, zonos ar siuntų duomenys.\n",
        "# reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])) funkcija sumažina duomenų kiekį,\n",
        "# apjungdama tokius tuple, kurių raktai sutampa ir išsaugo tų tuple reikšmes,\n",
        "# sumuojant jų siuntų ir klientų skaičių.\n",
        "ATS = A.flatMap(myfmap)\\\n",
        "    .map(mymap)\\\n",
        "    .filter(lambda x: x is not None)\\\n",
        "    .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
        "\n",
        "\n",
        "# Išvesti rezultatus\n",
        "print(ATS.collect())\n",
        "\n",
        "\n",
        "# sugeneruoti lentelės duomenis iš Spark rezultatų\n",
        "table_data = []\n",
        "for ((zona, diena), (siunta, klientai)) in ATS.collect():\n",
        "    row = {'zona': zona, 'savaites diena': diena, 'siuntu sk.': siunta, 'Sustojimo klientu sk.': klientai}\n",
        "    table_data.append(row)\n",
        "\n",
        "# sukurti pandas lentelę su gautais duomenimis\n",
        "df = pd.DataFrame(table_data)\n",
        "print(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irmV24HlxpKz",
        "outputId": "1d35b5e3-4e35-456a-e494-adc6bdec6845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('Z1', 3), 165), (('Z1', 2), 13), (('Z1', 0), 12), (('Z1', 4), 153)]\n",
            "  zona  savaites diena  siuntu sk.\n",
            "0   Z1               3         165\n",
            "1   Z1               2          13\n",
            "2   Z1               0          12\n",
            "3   Z1               4         153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B = open(\"text.txt\", \"r\")\n",
        "count = 0\n",
        "for line in B:\n",
        "  line = line.strip()\n",
        "  line = line[2:len(line) - 2]\n",
        "  count += 1\n",
        "  susstring = line.split('}}{{')\n",
        "print(count)"
      ],
      "metadata": {
        "id": "ubbXZshtxpN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0200cf-d70c-461f-87f0-7fd68c4d7a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_5QNH4qaDPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile(\"text.txt\")\n",
        "def myfmap(line):\n",
        "  line = line.strip()\n",
        "  line = line[2:len(line)-2]\n",
        "  return line.split('}}{{')\n",
        "def mymap(stopas):\n",
        "  #Sustojimo klientu skaicius\n",
        "  klientai = 0\n",
        "  #sustojimo savaites diena\n",
        "  diena = None\n",
        "  parstrings = stopas.split('}{')\n",
        "  for parstring in parstrings:\n",
        "    (vardas, reiksme) = parstring.split('=')\n",
        "    if(reiksme != ''):\n",
        "      if(vardas == 'Sustojimo klientu skaicius'):\n",
        "        klientai=int(reiksme)\n",
        "      if(vardas == 'sustojimo savaites diena'):\n",
        "        diena=int(reiksme)\n",
        "  #if(klientai != None and diena != None):\n",
        "  return (diena, klientai)\n",
        "ATS = A.flatMap(myfmap)\\\n",
        "  .map(mymap)\\\n",
        "  .filter(lambda kv : kv[0]!=None)\\\n",
        "  .reduceByKey(lambda a,b:a+b)\n",
        "#diena != None\n",
        "#print(sustojimai.take(10))\n",
        "print(ATS.take(10))\n",
        "print(ATS.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyTEtfHVy26h",
        "outputId": "fb01785c-f3e1-410d-fe95-9bb554581906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(2, 163), (4, 108), (3, 201), (5, 109), (1, 90)]\n",
            "[(2, 163), (4, 108), (3, 201), (5, 109), (1, 90)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIYY9FTeaDSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DhVT6xLSaDVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WpNhE03aDYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.parallelize([\"b\", \"a\", \"c\"])\n",
        "y = x.map(lambda z: (z, 1))\n",
        "\n",
        "def ma(z):\n",
        "  return [z, 1]\n",
        "\n",
        "print(x.collect())\n",
        "print(y.collect())\n",
        "# print(y2.collect())"
      ],
      "metadata": {
        "id": "abj0y3vO8Ip2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba7426d-fe30-445c-e046-1179cf56ad97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['b', 'a', 'c']\n",
            "[('b', 1), ('a', 1), ('c', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A = sc.textFile('pvz.txt')\n",
        "A = sc.parallelize([\"b\", \"a\", \"c\"])\n",
        "print(type(A.collect()))\n",
        "# def fum(w):\n",
        "#   if w!='b':\n",
        "#     return [w]\n",
        "#   else:\n",
        "#     return []\n",
        "y = A.flatMap(lambda z: [z] if z != 'b' else [])\n",
        "y2 = A.filter(lambda w: w != 'b')\n",
        "y3 = A.map(lambda v: v != 'b')\n",
        "print(y.collect())\n",
        "print(y2.collect())\n",
        "print(y3.collect())\n",
        "# y = A.flatMap(fum)\n",
        "# print(A.collect())\n",
        "# print(y.collect())\n",
        "# y2 = A.filter(lambda w : w!='b')\n",
        "# print(y2.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I--xzug0jX7w",
        "outputId": "47c869b1-05ef-43e7-bc62-593792e59d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['a', 'c']\n",
            "['a', 'c']\n",
            "[False, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x = sc.parallelize([1,2,3])\n",
        "x = sc.textFile(\"int.txt\")\\\n",
        ".map(lambda l: int(l))\n",
        "y = x.filter(lambda o: o%2 == 1) #keep odd values\n",
        "print(x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb6t5fw0ZcML",
        "outputId": "92c88d4a-912b-484d-f8b0-c52637ff03ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 56, 12, 5644, 654, 52165, 2, 65, 36321, 5]\n",
            "[1, 3, 52165, 65, 36321, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.parallelize([1,2,3])\n",
        "y = x.map(lambda x: [x, x*100, 42])\n",
        "fy = x.flatMap(lambda x: [x, x*100, 42])\n",
        "print(x.collect())\n",
        "print(y.collect())\n",
        "print(fy.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIbZAHHcatWu",
        "outputId": "42aa2942-e7e2-4607-9d86-0b770d0b6f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n",
            "[[1, 100, 42], [2, 200, 42], [3, 300, 42]]\n",
            "[1, 100, 42, 2, 200, 42, 3, 300, 42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = sc.textFile(\"text2.txt\")\n",
        "words = A.flatMap(lambda line: line.strip().split())\n",
        "print(words.take(10))\n",
        "pomap = words.map(lambda w: (w, 1))\n",
        "print(\"pomap:\", pomap.take(2))\n",
        "\n",
        "def red(a, b):\n",
        "  return a+b\n",
        "pored = pomap.reduceByKey(red)\n",
        "print(pored.collect())\n",
        "\n",
        "B = A.flatMap(lambda line: line.strip().split())\\\n",
        ".map(lambda w: (w, 1))\\\n",
        ".reduceByKey(red)\n",
        "print(B.collect())\n",
        "# print([(k, list(v)) for (k, v) in B.collect])"
      ],
      "metadata": {
        "id": "uhArpKILau4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4433d8e9-5acf-415b-df1f-6256365354b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Within', 'two', 'minutes,', 'or', 'even', 'less,', 'he', 'had', 'forgotten', 'all']\n",
            "pomap: [('Within', 1), ('two', 1)]\n",
            "[('Within', 1), ('two', 1), ('minutes,', 1), ('even', 2), ('less,', 1), ('he', 6), ('his', 11), ('troubles.', 1), ('Not', 1), ('troubles', 1), ('heavy', 1), ('than', 2), ('are', 2), ('but', 1), ('new', 5), ('interest', 2), ('them', 2), ('down', 2), ('drove', 1), ('out', 1), ('of', 11), ('mind', 1), ('as', 4), (\"men's\", 1), ('in', 6), ('excitement', 1), ('enterprises.', 1), ('was', 11), ('valued', 1), ('whistling,', 1), ('just', 1), ('acquired', 1), ('suffering', 1), ('It', 2), ('consisted', 1), ('bird-like', 1), ('produced', 1), ('touching', 1), ('mouth', 2), ('at', 3), ('short', 1), ('intervals', 1), ('midst', 1), ('music—the', 1), ('probably', 1), ('remembers', 1), ('do', 1), ('it,', 2), ('ever', 1), ('Diligence', 1), ('gave', 1), ('knack', 1), ('strode', 1), ('full', 2), ('harmony', 1), ('felt', 1), ('an', 2), ('feels', 1), ('far', 1), ('strong,', 1), ('deep,', 1), ('unalloyed', 1), ('is', 1), ('concerned,', 1), ('boy,', 1), ('The', 2), ('summer', 1), ('long.', 1), ('yet.', 1), ('Presently', 1), ('Tom', 3), ('before', 1), ('him—a', 1), ('boy', 3), ('shade', 1), ('larger', 1), ('impressive', 1), ('curiosity', 1), ('poor', 1), ('shabby', 1), ('St.', 1), ('Petersburg.', 1), ('dressed,', 1), ('too—well', 1), ('dressed', 1), ('week-day.', 1), ('astounding.', 1), ('cap', 1), ('closebuttoned', 1), ('shoes', 1), ('only', 2), ('Friday.', 1), ('bright', 1), ('ribbon.', 1), ('into', 1), (\"Tom's\", 1), ('more', 1), ('stared', 1), ('higher', 1), ('turned', 1), ('nose', 1), ('own', 1), ('seemed', 1), ('grow.', 1), ('Neither', 1), ('moved,', 1), ('other', 1), ('moved—but', 1), ('circle;', 1), ('kept', 1), ('Finally', 1), ('or', 2), ('had', 4), ('forgotten', 2), ('all', 2), ('because', 2), ('were', 3), ('one', 2), ('whit', 1), ('less', 1), ('and', 12), ('bitter', 1), ('to', 9), ('him', 4), ('a', 16), (\"man's\", 1), ('man,', 1), ('powerful', 1), ('bore', 1), ('for', 1), ('the', 18), ('time—just', 1), ('misfortunes', 1), ('This', 3), ('novelty', 1), ('which', 1), ('from', 1), ('negro,', 1), ('practise', 1), ('it', 2), ('un-disturbed.', 1), ('peculiar', 1), ('turn,', 1), ('sort', 1), ('liquid', 1), ('warble,', 1), ('by', 1), ('tongue', 1), ('roof', 1), ('reader', 1), ('how', 1), ('if', 1), ('has', 2), ('been', 1), ('boy.', 1), ('attention', 1), ('soon', 1), ('street', 1), ('with', 2), ('soul', 1), ('gratitude.', 1), ('He', 4), ('much', 1), ('astronomer', 1), ('who', 1), ('discovered', 1), ('planet—no', 1), ('doubt,', 1), ('pleasure', 1), ('advantage', 1), ('not', 2), ('astronomer.', 1), ('evenings', 1), ('dark,', 1), ('checked', 1), ('whistle.', 1), ('A', 2), ('stranger', 1), ('himself.', 1), ('newcomer', 1), ('any', 1), ('age', 1), ('either', 1), ('sex', 1), ('little', 1), ('village', 1), ('well', 1), ('on', 1), ('simply', 1), ('His', 1), ('dainty', 1), ('thing,', 1), ('blue', 1), ('cloth', 1), ('roundabout', 1), ('natty,', 1), ('so', 1), ('pantaloons.', 1), ('on—and', 1), ('wore', 1), ('necktie,', 1), ('bit', 1), ('citified', 1), ('air', 1), ('about', 1), ('that', 1), ('ate', 1), ('vitals.', 1), ('splendid', 1), ('marvel,', 1), ('up', 1), ('finery', 1), ('shabbier', 2), ('outfit', 1), ('spoke.', 1), ('If', 1), ('sidewise,', 1), ('they', 1), ('face', 2), ('eye', 2), ('time.', 1), ('said:', 1)]\n",
            "[('Within', 1), ('two', 1), ('minutes,', 1), ('even', 2), ('less,', 1), ('he', 6), ('his', 11), ('troubles.', 1), ('Not', 1), ('troubles', 1), ('heavy', 1), ('than', 2), ('are', 2), ('but', 1), ('new', 5), ('interest', 2), ('them', 2), ('down', 2), ('drove', 1), ('out', 1), ('of', 11), ('mind', 1), ('as', 4), (\"men's\", 1), ('in', 6), ('excitement', 1), ('enterprises.', 1), ('was', 11), ('valued', 1), ('whistling,', 1), ('just', 1), ('acquired', 1), ('suffering', 1), ('It', 2), ('consisted', 1), ('bird-like', 1), ('produced', 1), ('touching', 1), ('mouth', 2), ('at', 3), ('short', 1), ('intervals', 1), ('midst', 1), ('music—the', 1), ('probably', 1), ('remembers', 1), ('do', 1), ('it,', 2), ('ever', 1), ('Diligence', 1), ('gave', 1), ('knack', 1), ('strode', 1), ('full', 2), ('harmony', 1), ('felt', 1), ('an', 2), ('feels', 1), ('far', 1), ('strong,', 1), ('deep,', 1), ('unalloyed', 1), ('is', 1), ('concerned,', 1), ('boy,', 1), ('The', 2), ('summer', 1), ('long.', 1), ('yet.', 1), ('Presently', 1), ('Tom', 3), ('before', 1), ('him—a', 1), ('boy', 3), ('shade', 1), ('larger', 1), ('impressive', 1), ('curiosity', 1), ('poor', 1), ('shabby', 1), ('St.', 1), ('Petersburg.', 1), ('dressed,', 1), ('too—well', 1), ('dressed', 1), ('week-day.', 1), ('astounding.', 1), ('cap', 1), ('closebuttoned', 1), ('shoes', 1), ('only', 2), ('Friday.', 1), ('bright', 1), ('ribbon.', 1), ('into', 1), (\"Tom's\", 1), ('more', 1), ('stared', 1), ('higher', 1), ('turned', 1), ('nose', 1), ('own', 1), ('seemed', 1), ('grow.', 1), ('Neither', 1), ('moved,', 1), ('other', 1), ('moved—but', 1), ('circle;', 1), ('kept', 1), ('Finally', 1), ('or', 2), ('had', 4), ('forgotten', 2), ('all', 2), ('because', 2), ('were', 3), ('one', 2), ('whit', 1), ('less', 1), ('and', 12), ('bitter', 1), ('to', 9), ('him', 4), ('a', 16), (\"man's\", 1), ('man,', 1), ('powerful', 1), ('bore', 1), ('for', 1), ('the', 18), ('time—just', 1), ('misfortunes', 1), ('This', 3), ('novelty', 1), ('which', 1), ('from', 1), ('negro,', 1), ('practise', 1), ('it', 2), ('un-disturbed.', 1), ('peculiar', 1), ('turn,', 1), ('sort', 1), ('liquid', 1), ('warble,', 1), ('by', 1), ('tongue', 1), ('roof', 1), ('reader', 1), ('how', 1), ('if', 1), ('has', 2), ('been', 1), ('boy.', 1), ('attention', 1), ('soon', 1), ('street', 1), ('with', 2), ('soul', 1), ('gratitude.', 1), ('He', 4), ('much', 1), ('astronomer', 1), ('who', 1), ('discovered', 1), ('planet—no', 1), ('doubt,', 1), ('pleasure', 1), ('advantage', 1), ('not', 2), ('astronomer.', 1), ('evenings', 1), ('dark,', 1), ('checked', 1), ('whistle.', 1), ('A', 2), ('stranger', 1), ('himself.', 1), ('newcomer', 1), ('any', 1), ('age', 1), ('either', 1), ('sex', 1), ('little', 1), ('village', 1), ('well', 1), ('on', 1), ('simply', 1), ('His', 1), ('dainty', 1), ('thing,', 1), ('blue', 1), ('cloth', 1), ('roundabout', 1), ('natty,', 1), ('so', 1), ('pantaloons.', 1), ('on—and', 1), ('wore', 1), ('necktie,', 1), ('bit', 1), ('citified', 1), ('air', 1), ('about', 1), ('that', 1), ('ate', 1), ('vitals.', 1), ('splendid', 1), ('marvel,', 1), ('up', 1), ('finery', 1), ('shabbier', 2), ('outfit', 1), ('spoke.', 1), ('If', 1), ('sidewise,', 1), ('they', 1), ('face', 2), ('eye', 2), ('time.', 1), ('said:', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6w0HRhgy2vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dfQMt3en3ta9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GnLSbBG3tp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdjCos2u3tss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cIqlaqZ6y3BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76Ktlj-qy3EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JwhU5Tx0y3Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bz3KYzSy3Kh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}